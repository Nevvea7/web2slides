<!DOCTYPE html>
<html>
  <head>
    <title>NYU OS 202 Lecture Slides</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
 _Contents generated from: http://cs.nyu.edu/~gottlieb/courses/os202/class-notes.html_

Start Lecture #4



---
## 1.7 Operating System Structure

I must note that Tanenbaum is a big advocate of the so called microkernel
approach in which as much as possible is moved out of the (supervisor mode)
kernel into separate processes. The (hopefully small) portion left in
supervisor mode is called a microkernel.

In the early 90s this was popular. Digital Unix (subsequently called True64)
and Windows NT/2000/XP/Vista/7/8 are examples. Digital Unix was based on Mach,
a research OS from Carnegie Mellon university. Lately, the growing popularity
of Linux has called into question the belief that all new operating systems
will be microkernel based.



---
### 1.7.1 Monolithic approach

The previous picture: one big program.

The system switches from user mode to kernel mode during the trap and then
back when the OS does an RTI (return from interrupt).

While in supervisor mode, the OS naturally includes procedure calls and
returns.

Modern monolithic systems, such as Windows and Linux, are not completely
monolithic in that during execution, they can load code modules as needed.
This load on demand capability is mainly used for device drivers.

We can structure the system better than above might suggest, which brings us
to ...



---
![layers](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/layers.png)



---
### 1.7.2 Layered Systems

Some systems have more layers and are more strictly structured.

An early layered system was THE operating system by Dijkstra and his students
at Technische Hogeschool Eindhoven. This was a simple batch system so the
operator was the user.

The actual layers were

  1. The operator process
  2. User programs
  3. I/O mgt
  4. Operator console--process communication
  5. Memory and drum management

The layering was done by convention, i.e. there was no enforcement by hardware
and the entire OS is linked together as one program. This is true of many


---
modern OS systems as well (e.g., linux).

The MULTICS system was layered in a more formal manner. The hardware provided
several protection layers and the OS used them. That is, arbitrary code could
not jump into or access data in a more protected layer.



---
### 1.7.3 Microkernels

The idea is to have the kernel, i.e. the portion running in supervisor mode,
as small as possible and to have most of the operating system functionality
provided by separate processes. The _microkernel_ provides just enough to
implement processes.

![microkernel](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/microkern

---
el.
png)

This does have advantages. For example an error in the file server cannot
corrupt memory in the process server since they have separate address spaces
(they are after all separate process). Confining the effect of errors makes
them easier to track down. Also an error in the ethernet driver can corrupt or
stop network communication, but it _cannot_ crash the system as a whole.

But the microkernel approach does mean that when a (real) user process makes a
system call there are more processes switches. These are not free.

Related to microkernels is the idea of putting the mechanism in the kernel,
but not the policy. For example, the kernel would know how to select the
highest priority process and run it, but some external process would assign

---

the priorities. In this way changing the priority scheme could become a
relatively minor event compared to the situation in monolithic systems where
the entire kernel must be relinked and rebooted.

#### Microkernels Not So Different In Practice

Dennis Ritchie, the inventor of the C programming language and co-inventor,
with Ken Thompson, of Unix was interviewed in February 2003\. The following is
from that interview.

What's your opinion on microkernels vs. monolithic?

> They're not all that different when you actually use them. Micro kernels
tend to be pretty large these days, monolithic kernels with loadable device
drivers are taking up more of the advantages claimed for microkernels.


---

I should note, however, that Tanenbaum's Minix microkernel (excluding the
processes) _is_ quite small, about 13,000 lines.



---
### 1.7.4 Client-Server

When implemented on one computer, a client-server OS often uses the
microkernel approach shown above in which the microkernel just handles
communication between clients and servers, and the main OS functions are
provided by a number of separate processes.

A _distributed system_ can be thought of as an extension of the client server
concept where the servers are remote.



---
![dist-client-server](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/dist-
client-server.png)

The figure on the right would describe a distributed system of yesteryear,
where memory was scarce and it would be considered lavish to have full systems
on each machine.

Today with plentiful memory, each machine would have all the different
servers. So the only reason an OS-internal message would go to another
computer is if the originating process wished to communicate with a specific
process on that computer (for example needed to access a remote disk).

Distributed systems are becoming increasingly important for application
programs. Perhaps the program needs data found only on certain machine (no one
machine has all the data). For example, think of (legal, of course) file
sharing programs.  


---
  
Distributed systems are also used to reduce the time required by an
application. You do this by dividing the program into pieces, which are run
concurrently on separate computers.

**Homework:** The client-server model is popular in distributed systems. Can it also be used in single-computer system?



---
### 1.7.5 Virtual Machines

Use a hypervisor (i.e., beyond supervisor, i.e. beyond a normal OS) to switch
between multiple _Operating Systems_. The modern name for a hypervisor is a
Virtual Machine Monitor (VMM).

#### VM/370



---
![hypervisor](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/hypervisor.pn
g)

The hypervisor idea was made popular by IBM's CP/CMS (now VM/370). CMS stood
for Cambridge Monitor System since it was developed at IBM's Cambridge (MA)
Science Center. It was renamed, with the same acronym (an IBM specialty, cf.
RAID) to Conversational Monitor System.

  * Each App/CMS runs on a _virtual_ 370.
  * CMS is a _single user_ OS.
  * A system call in an App (application) traps to the corresponding CMS.
  * CMS believes it is running on the actual hardware so issues I/O instructions but ...
  * ... I/O instructions in CMS trap to VM/370.
  * This idea is still used but the guest OS is now normally a full-featured operating system rather than a simple system like CMS. For example, the n

---
ewest IBM systems can run multiple instances of linux as well as multiple instances of traditional IBM Operating Systems on a single hardware platform.

#### Virtual Machines Redicovered

Recently, virtual machine technology has moved to machines (notably x86) that
are not fully virtualizable. Recall that when CMS executed a privileged
instruction, the hardware trapped to the real operating system. On x86,
privileged instructions are _ignored_ when executed in user mode, so running
the guest OS in user mode won't work. Bye bye (traditional) hypervisor. But a
new style emerged where the hypervisor runs, not on the hardware, but on the
host operating system. See the text for a sketch of how this (and another idea
paravirtualization) works. An important research advance was Disco from
Stanford University that led to the successful commercial product VMware.


---

##### Sanity Restored

Both AMD and Intel have extended the x86 architecture to better support
virtualization. The newest processors produced today (2008) by both companies
now support an additional (higher) privilege mode for the VMM. The guest OS
now runs in the old privileged mode (for which it was designed) and the
hypervisor/VMM runs in the new higher privileged mode from which it is able to
monitor the usage of hardware resources by the guest operating system(s).

#### The Java Virtual Machine

The idea is that a new (rather simple) computer architecture called the Java
Virtual Machine (JVM) was invented but not built (in hardware). Instead,
interpreters for this architecture are implemented in software on many
different hardware platforms. Each interpreter is also called a JVM. The ja

---
va
compiler transforms java into instructions for this new architecture, which
then can be interpreted on any machine for which a JVM exists.

This has portability as well as security advantages, but at a cost in
performance.

Of course java can also be compiled to native code for a particular hardware
architecture and other languages can be compiled into instructions for a
software-implemented virtual machine (e.g., pascal with its p-code).



---
### 1.7.6 Exokernels

Similar to VM/CMS but the virtual machines have disjoint resources (e.g.,
distinct disk blocks) so less remapping is needed.



---
## 1.8 The World According to C



---
### 1.8.1 The C Language

Assumed knowledge.



---
### 1.8.2 Header Files

Assumed knowledge.



---
### 1.8.3 Large Programming Projects

Mostly assumed knowledge. Linker's are very briefly discussed. Our earlier
discussion was much more detailed.



---
### 1.8.4 The model of Run Time

Extremely brief treatment with only a few points made about the running of the
operating itself.

  * The text (code) segment is normally read only.
  * The stack is initially of size zero; it grows and shrinks as functions are called and return.
  * The data segment is initially not empty, with some of it initialized. It can grow under program control and perhaps can shrink.



---
## 1.9 Research on Operating Systems

Skipped



---
## 1.10 Outline of the Rest of this Book

Skipped



---
## 1.11 Metric Units

Assumed knowledge. Note that what is covered is just the prefixes, i.e. the
names and abbreviations for various powers of 10.



---
## 1.12 Summary

Skipped, but you should read and be sure you understand it (about 2/3 of a
page).



---
# Chapter 2 Process and Thread Management

Tanenbaum's chapter title is Processes and Threads. I prefer to add the word
management. The subject matter is processes, threads, scheduling, interrupt
handling, and IPC (Inter-Process Communication--and Coordination).



---
## 2.1 Processes

**Definition:** A **process** is a program in execution.

  * We are assuming a **multiprogramming** OS that can switch from one process to another.
  * Sometimes this is called _pseudoparallelism_ since one has the illusion of a parallel processor.
  * The other possibility is _real parallelism_ in which two or more processes are actually running at once because the computer system is a parallel processor, i.e., has more than one processor.
  * We do not study real parallelism (parallel processing, distributed systems, multiprocessors, etc) in this course.



---
### 2.1.1 The Process Model

![multiprogramming](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/multipr
ogramming.png)

Even though in actuality there are many processes running at once, the OS
gives each process the _illusion_ that it is running alone.

#### Virtual Time


---

Virtual time is the time used by just this processes. Virtual time progresses
at a rate independent of other processes.  (Actually, this is false, the
virtual time is typically incremented a little during the systems calls used
for process switching; so if there are other processes, overhead virtual time
occurs.)

#### Virtual Memory

Virtual memory is the memory as viewed by the process. Each process typically
believes it has a contiguous chunk of memory starting at location zero. Of
course this can't be true of all processes (or they would be using the same
memory) and in modern systems it is actually true of no processes (the memory
assigned to a single process is not contiguous and does not include locatio

---
n
zero).  
  
Think of the individual modules that are input to the linker. Each numbers its
addresses from zero; the linker eventually translates these relative addresses
into absolute addresses. That is the linker provides to the assembler a
virtual memory in which addresses start at zero.

Virtual time and virtual memory are examples of abstractions provided by the
operating system to the user processes so that the latter experiences a more
pleasant virtual machine than actually exists.

**Remark**: Please note that the problem numbers are from the fourth edition. They are not the same problems in older editions.



---
### 2.1.2 Process Creation

From the users' or external viewpoint there are several mechanisms for
creating a process.

  1. System initialization, including daemon (see below) processes.
  2. Execution of a process creation system call (fork()) by a running process.
  3. A user request to create a new process.
  4. Initiation of a batch job.

But looked at internally, from the system's viewpoint, the second method
dominates. Indeed, in early versions of Unix only one process (called _init_)
is created at system initialization; all the others are created by the
`fork()` system call.

**Question**: Why have init? That is why not have all processes created via method 2?  
**Answer**: Because without init there would be no running process to creat

---
e any others.

#### Definition of Daemon

Many systems have daemon process lurking around to perform tasks when they are
needed. I was pretty sure the terminology was related to mythology, but didn't
have a reference until a student  found The {Searchable} Jargon Lexicon at
http://developer.syndetic.org/query_jargon.pl?term=demon

> daemon: /day'mn/ or /dee'mn/ n. [from the mythological meaning, later
rationalized as the acronym `Disk And Execution MONitor'] A program that is
not invoked explicitly, but lies dormant waiting for some condition(s) to
occur. The idea is that the perpetrator of the condition need not be aware
that a daemon is lurking (though often a program will commit an action only
because it knows that it will implicitly invoke a daemon). For example, under


---
ITS (a very early OS), writing a file on the LPT spooler's directory would
invoke the spooling daemon, which would then print the file. The advantage is
that programs wanting (in this example) files printed need neither compete for
access to nor understand any idiosyncrasies of the LPT. They simply enter
their implicit requests and let the daemon decide what to do with them.
Daemons are usually spawned automatically by the system, and may either live
forever or be regenerated at intervals. Daemon and demon are often used
interchangeably, but seem to have distinct connotations. The term `daemon' was
introduced to computing by CTSS people (who pronounced it /dee'mon/) and used
it to refer to what ITS called a dragon; the prototype was a program called
DAEMON that automatically made tape backups of the file system. Although the
meaning and the pronunciation have drifted, we think this glossary reflects


---
current (2000) usage.

As is often the case, wikipedia.org proved useful. Here is the first paragraph
of a much larger entry. The wikipedia also has entries for other uses of
daemon.

> In Unix and other computer multitasking operating systems, a daemon is a
computer program that runs in the background, rather than under the direct
control of a user; they are usually instantiated as processes. Typically
daemons have names that end with the letter "d"; for example, syslogd is the
daemon which handles the system log.



---
### 2.1.3 Process Termination

Again from the outside there appear to be several termination mechanism.

  1. Normal exit (voluntary).
  2. Error exit (voluntary).
  3. Fatal error (involuntary).
  4. Killed by another process (involuntary).

And again, internally the situation is simpler. In Unix terminology, there are
two system calls _kill()_ and _exit()_ that are used. kill() (poorly named in
my view) sends a signal to another process. For many types of signals, if the
signal is not caught (via the signal() or sigaction() system call) the process
is terminated. There is also an uncatchable signal. The exit() system call is
used for self termination and can indicate success or failure.


---

![process-hier](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/process-
hier.png)



---
### 2.1.4 Process Hierarchies

Modern general purpose operating systems permit a user to create and destroy
processes.

  * In unix this is done by the **fork()** system call, which creates a **child** process, and the **exit** system call, which terminates the current process.
  * After a fork both parent and child keep running (indeed they have the _same_ program text) and each can fork off other processes.
  * A process tree results. The root of the tree is a special process created by the OS during startup.
  * A process can _choose_ to wait for children to terminate. For example, if C issued a wait() system call mentioning G, C would block until G finished.

Old or primitive operating system like MS-DOS are not fully multiprogrammed,
so when one process starts another, the first process is _automatically_


---
blocked and waits until the second is finished. This implies that the process
tree degenerates into a line.



---
### 2.1.5 Process States and Transitions

The diagram on the right contains much information. I often include it on
exams.

![process-states](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/process-
states.png)

Consider a running process P that issues an I/O request.


---

  * The process blocks.
  * At some later point, a disk interrupt occurs and the driver detects that P's request is satisfied.
  * P is unblocked, i.e. is moved from blocked to ready
  * At some later time the operating system scheduler looks for a ready job to run and picks P.

A preemptive scheduler has the dotted line preempt;  
A non-preemptive scheduler doesn't.

The number of processes changes only for two arcs: create and terminate.

Suspend and resume are medium term scheduling.

  * Done on a longer time scale.
  * Involves memory management as well. As a result we study it later.
  * Sometimes called two level scheduling.


---
![fig-2-3](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/fig-2-3.png)

As mentioned previously, one can organize an OS around the scheduler.

  * Write a minimal kernel (a micro-kernel) consisting of the scheduler, interrupt handlers, and IPC (interprocess communication).
  * The rest of the OS consists of kernel processes (e.g. memory, filesystem) that act as servers for the user processes (which of course act as clients).
  * The system processes also act as clients of other system processes.
  * The above is called the client-server model and is one Tanenbaum likes. His Minix operating system works this way.
  * Indeed, there was reason to believe that the client-server model would dominate OS design. But that hasn't happened.
  * Such an OS is sometimes called _server based_.
  * Systems like traditional Unix or Linux are then called _self-service_ since the user process serves itself. That is, the user process switches to kernel mode (via the TRAP instruction) and performs the system call itself without transferring control to another process.



---
### 2.1.6 Implementation of Processes

The OS organizes the data about each process in a table naturally called the
**process table**. Each entry in this table is called a **process table
entry** or **process control block**.

Characteristics of the process table.

  * One entry per process.
  * The central data structure for process management.
  * A process state transition (e.g., moving from blocked to ready) is reflected by a change in the value of one or more fields in the process control block.
  * We have converted an active entity (a process) into a data structure (a process control block). Finkel calls this the _level principle_ an active entity becomes a data structure when looked at from a lower level.
  * The process control block contains a great deal of information about the process. For example, 
    * Saved value of registers including the program counter (i.e., the add

---
ress of the next instruction) when the process not running.
    * Stack pointer.
    * CPU time used.
    * Process id (PID).
    * Process id of parent (PPID).
    * User id (uid.
    * Group id (gid).
    * Pointer to text segment (memory for the instructions).
    * Pointer to data segment.
    * Pointer to stack segment.
    * UMASK (default permissions for new files).
    * Current working directory.
    * Many others.

</textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>