<!DOCTYPE html>
<html>
  <head>
    <title>NYU OS 202 Lecture Slides</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
 _Contents generated from: http://cs.nyu.edu/~gottlieb/courses/os202/class-notes.html_

Start Lecture #13

**Remarks**

  1. Solutions to chapter 2 homework problems are on nyu classes.
  2. Answers to the practice midterm are on the web.

#### ** (Non-Demand) Paging

![mapping-pages](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/mapping

---
-
pages.png)

Paging is the simplest scheme to remove the requirement of contiguous physical
memory and the potentially large external fragmentation that it causes..

  * The program is logically divided into fixed size pieces called **pages**. The partitioning is invisible to the user.
  * This is a division of the virtual address space and is shown in the middle column on the right.
  * Tanenbaum (and others) sometimes calls pages **virtual pages**.
  * The physical memory is similarly divided into fixed size pieces called **page frames.**
  * This is a division of the physical address space and is shown in the third column on the right.
  * Page frames are often called simply **frames**.
  * The size of a page (the page size) equals the size of a frame (the frame size).
  * Place each page in a frame. Since all pages and all frames are the same

---
 size everything fits perfectly and there is no external fragmentation.
  * Note that the program is **not** contiguous in physical memory. For example, in the diagram page 1 comes **after** page page 2 in physical memory. How can this possible work?
  * We need to find an arbitrary **vritual** address in **physical** memory.
  * The key is that the OS maintains a table (called the **page table**) having an entry for each page. The **page table entry** or PTE for page p contains the number of the frame f that contains page p.
![paging](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/paging.png)  


---

##### Virtual to Physical Address Translation

The figure on the right shows how to translate a virtual address into the
corresponding physical address, i.e. how to find where in physical memory a
given virtual address resides.

  1. The address is divided into two part: the page number and the offset. The page number equals the (virtual) address divided by the page size. The offset equals the address mod the page size.
  2. The page number is used to index the page table.
  3. The table entry gives the frame number for this page.
  4. The frame number is combined with the offset to obtain the physical address. Specifically the physical address is  
  frame number times frame size plus offset.

**Example:** Given a machine with page size (PS) = frame size = 1000.  
What is the physical address (PA) corresponding to the virtual address (VA) =


---
3372?

  1. The page number is p# = VA / PS = 3372 / 1000 = 3
  2. The offset O = VA % PS = 3372 % 1000 = 372.
  3. The frame number f# is the contents of PTE[3].
  4. Assume PTE 3 contains 459.
  5. Then VA 3372 translates to   
  PA = f# * FS + O= 459 * 1000 + 372 = 459372.

  6. Referring to the diagram p#=3, f#=459, and offset=372.

Properties of (non-demand) paging (without segmentation).

  * The entire process must be memory resident to run.
  * The physical address is **not** continuous, i.e., the memory image of the program consists of several pieces. 
  * The virtual address space remains contiguous.
  * No holes, i.e., no external fragmentation.
  * If there are 500 frames available and the page size is 4KB, then any job requiring â‰¤ 2MB will fit, even if the available frames are scattered ov

---
er memory.
  * Hence (non-demand) paging is useful; indeed, it was used (but no longer).
  * Introduces internal fragmentation approximately equal to 1/2 the page size for every process (really every segment).
  * Can have a job unable to run due to insufficient memory and have some (but not enough) memory available. This is _not_ called external fragmentation since it is not due to memory being fragmented.
  * Eliminates the _placement_ question. All pages are equally good since don't have external fragmentation.
  * The _replacement_ question remains.
  * Since page boundaries occur at random points in the program and can change from run to run (the page size can change with no effect on the program--other than performance), pages are not appropriate units of memory to use for protection and sharing. Segmentation, which is discussed later, is sometimes more appropriate for protection and sharing.
  * However, most current OSes do not have segmentation so they use pages for protection and sharing. If all you have is a hammer, everything looks like a nail.
  


---

##### Cost of Address Translation in Paging

There seems to be a bunch of arithmetic and an extra memory reference (to the
page table) required, which would make the scheme totally impractable.

The arithmetic is not needed. Indeed you and I can divide by 1000 (the page
size) or take mod 1000 in our heads by separating the rightmost three digits
from the rest. That is because 1000 is 103 and we write numbers in decimal.

Computers use binary so designers choose the page size to be a power of two
and again dividing and and taking mods simply require separating the leftmost
digits from the rightmost.



---
It does seem as though each memory reference turns into 2 memory references.

  1. Reference the page table.
  2. Reference central memory.

This would indeed be a disaster! But it isn't done that way. Instead,the MMU
caches page#->frame# translations. This cache is kept near the processor and
can be accessed rapidly.

This cache is called a translation lookaside buffer (TLB) or translation
buffer (TB).

For the above example, after referencing virtual address 3372, there would be
an entry in the TLB containing the mapping 3->459.

Hence a subsequent access to virtual address 3881 would be translated to


---
physical address 459881 without an extra memory reference. Naturally, a memory
reference for location 459881 itself would be required.

Choosing the page size is discuss below.

**Homework:** 7\. Using the page table of Fig. 3.9, give the physical address corresponding to each of the following virtual addresses.

  1. 20
  2. 4100
  3. 8300



---
## 3.3: Virtual Memory (meaning Fetch on Demand)

The idea is to enable a program to execute even if only the active portion of
its address space is memory resident. That is, we are to swap in and swap out
**portions** of a program and can run a program even if some (perhaps most) of
the program is **not** in memory.

In a crude sense this could be called automatic overlays.

Advantages

  * The system can run a program larger than the total physical memory, i.e., the virtual address size of the process can exceed the physical address size of the computer.
  * Even if each program is smaller than physical memory, the sum of the memory of all the running programs can exceed physical memory.
  * Fetch-on-demand likely increase the multiprogramming level since the to

---
tal size of the active, i.e. loaded, programs (running + ready + blocked) can exceed the size of the physical memory.
  * Since some portions of a program are rarely if ever used, it is an inefficient use of memory to have them loaded all the time. Fetch-on-demand will not load them if not used and will (hopefully) unload them in favor of other portions if they are not used for a long time.
  * Simpler for the **user** than overlays or aliasing variables (older techniques to run large programs using limited memory).

Disadvantages

  * More complicated for the OS.
  * Execution time less predictable (depends on other jobs).
  * Can over-commit memory (more on this later).

#### The Memory Management Unit and Virtual to Physical Address Translation

The memory management unit is a piece of hardware in the processor that,
together with the OS, translates virtual addresses (i.e., the addresses in 

---
the
program) into physical addresses (i.e., real hardware addresses in the
memory). The memory management unit is abbreviated as and normally referred to
as the **MMU**.

(The idea of an MMU and virtual to physical address translation applies
equally well to non-demand paging and in olden days the meaning of paging and
virtual memory included that case as well. Sadly, in my opinion, modern usage
of the term paging and virtual memory are limited to fetch-on-demand memory
systems, typically some form of demand paging.)



---
### ** 3.3.1 Paging (Meaning Demand Paging)

The idea is to fetch pages from disk to memory when they are referenced,hoping
to get the most actively used pages in memory. The choice of page size is
discussed below.

Demand paging is very common: More complicated variants, multilevel-level
paging and paging plus segmentation (both of which we will discuss), have been
used and the former dominates modern operating systems.

Started by the Atlas system at Manchester University in the 60s (paper by
Fortheringham).



---
![demand-paging](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/demand-
paging.png)

Each PTE continues to contain the frame number if the page is loaded. But what
if the page is not loaded (i.e., the page exists only on disk)?

The PTE has a flag indicating if the page is loaded (can think of the X in the
diagram on the right as indicating that this flag is not set). If the page is
not loaded, the location on disk could be kept in the PTE, but normally it is
not (discussed below).

When a reference is made to a non-loaded page (sometimes called a non-existent
page, but that is a bad name), the system has a lot of work to do. (We give


---
more details below.)

  1. Choose a free frame, if one exists.
  2. What if there is no free frame?  
Make one!

    1. Choose a victim frame. This is the **replacement** question about which we will have **much** more to say latter.
    2. Write the victim back to disk if it is dirty.
    3. Update the victim PTE to show that it is not loaded.
    4. Now we have a free frame.
  3. Copy the referenced page from disk to the free frame.
  4. Update the PTE of the referenced page to show that it is loaded and give the frame number.
  5. Do the standard paging address translation (p#,off)->(f#,off).

Really not done quite this way as we shall see later

**Homework:** 14\. A machine has a 32-bit address space and an 8-KB page. The page table is entirely in hardware, with one 32-bit word per entry. When

---
 a process starts, the page table is copied to the hardware from memory, at one word every 100 nsec. If each process runs for 100 msec (including the time to load the page table), what fraction of the CPU time is devoted to loading the page tables?



---
### 3.3.2 Page tables

A discussion of page tables is also appropriate for (non-demand) paging, but
the issues are more important with demand paging for at least two reasons.

  1. The total size of the active processes is no longer limited to the size of physical memory. Since the total size of the processes is greater, the total size of the page tables is greater and hence concerns over the size of the page table are more acute.
  2. With demand paging an important question is the choice of a victim page to page out. Data in the page table can be useful in this choice.

We must be able access to the page table very quickly since it is needed for
every memory access.



---
![big-page-table](http://cs.nyu.edu/~gottlieb/courses/os202/diagrams/big-page-
table.png)

Unfortunate laws of hardware.

  * Big and fast are essentially incompatible.
  * Big and fast and low cost is hopeless.

So we can't just say, put the page table in fast processor registers, and let
it be huge, and sell the system for $1000.

The simplest solution is to put the page table in main memory as shown on the
right. However this solution seems to be both too slow and too big.

  * The solution seems too slow since all memory references now require two reference.
  * We will soon see how to largely eliminate the extra reference by using 

---
a TLB.
  * The solution seems too big. 
    * Currently we are considering _contiguous_ virtual addresses ranges (i.e., the virtual addresses have no holes).
    * One often puts the stack at one end of the virtual address space and the global (or static) data at the other end and let them grow towards each other.
    * The **virtual** memory in between is unused and can be enormous.
    * That does **not** sound so bad. Why should we care about virtual memory?
    * Since unused virtual memory can be huge (in address range), the page table, which is stored in **real** memory, will mostly contain unneeded PTEs.
    * This scheme worked fine when the maximum virtual address size was comparable in size with the total physical address space (e.g., the PDP-11 of the 1970s) but that is no longer the case.
  * A fix is to use multiple levels of mapping. We will see two examples below: multilevel page tables and segmentation plus paging.

</textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>